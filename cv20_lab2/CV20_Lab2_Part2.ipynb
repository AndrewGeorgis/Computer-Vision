{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Μέρος 2: Εντοπισμός Χωρο-χρονικών Σημείων Ενδιαφέροντος και Εξαγωγή Χαρακτηριστικών σε Βίντεο Ανθρωπίνων Δράσεων\n",
    "\n",
    "Ανδρέας Γεωργής 03115194 \n",
    "\n",
    "Κούβαρης Σταύρος 03114090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import cv20_lab1_part2_utils  as ut\n",
    "from scipy.ndimage import convolve1d\n",
    "import cv20_lab2_part2_material as l2\n",
    "from cv20_lab2_part2_material import cv20_lab2_2_utils  as ut2\n",
    "from sklearn.preprocessing import normalize\n",
    "import LucasKanade as lk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Εισαγωγή βίντεο"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\Andrew\\\\anaconda3\\\\envs\\\\cv_lab\\\\CV20_Lab2\\\\cv20_lab2_part2_material\\\\boxing\\\\person06_boxing_d1_uncomp.avi\"\n",
    "nframes = 200\n",
    "video = ut2.read_video(path,nframes,0),\n",
    "vid = video[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Χωρο-χρονικά Σημεία Ενδιαφέροντος\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Υλοποιήση 3D Harris-Stephens και Gabor ανιχνευτή"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Harris_Stephens(video ,sigma, s , t , k ,theta):\n",
    "    n = int((np.ceil(3*sigma) * 2 + 1))\n",
    "    # create 2D Gaussian spatial kernel and 1D Gaussian time kernel\n",
    "    G_1D = cv2.getGaussianKernel(n, sigma)\n",
    "    G_2D = G_1D @ G_1D.T\n",
    "    nt =  int((np.ceil(3*t) * 2 + 1))\n",
    "    G_t = cv2.getGaussianKernel(nt, t)\n",
    "    \n",
    "    # weights = [-1,0,1]T mask for calculating derivatives \n",
    "    weights = np.array([-1,0,1])\n",
    "    L = np.empty(video.shape)\n",
    "    \n",
    "    # calculate L\n",
    "    for i in range(video.shape[2]):\n",
    "        L[:,:,i] = cv2.filter2D(cv2.filter2D(video[:,:,i],-1,G_2D),-1,G_t)\n",
    "       \n",
    "    # calculate second order derivatives of L \n",
    "    Lx = convolve1d(L,weights.T,axis=0)\n",
    "    Ly = convolve1d(L,weights.T,axis=1)\n",
    "    Lt = convolve1d(L,weights.T,axis=2)\n",
    "    Lxx = Lx**2\n",
    "    Lxy = Lx*Ly\n",
    "    Lxt = Lx*Lt\n",
    "    Lyy= Ly**2\n",
    "    Lyt = Ly*Lt\n",
    "    Ltt = Lt**2\n",
    "    \n",
    "    # calculate M\n",
    "    Mxx = cv2.filter2D(cv2.filter2D(Lxx,-1,G_2D),-1,G_t)\n",
    "    Myy = cv2.filter2D(cv2.filter2D(Lyy,-1,G_2D),-1,G_t)\n",
    "    Mtt= cv2.filter2D(cv2.filter2D(Ltt,-1,G_2D),-1,G_t)\n",
    "    Mxt = cv2.filter2D(cv2.filter2D(Lxt,-1,G_2D),-1,G_t)\n",
    "    Myt = cv2.filter2D(cv2.filter2D(Lyt,-1,G_2D),-1,G_t)\n",
    "    Mxy = cv2.filter2D(cv2.filter2D(Lxy,-1,G_2D),-1,G_t)\n",
    "    # Corner criterion\n",
    "    trM = Mxx + Myy + Mtt\n",
    "    dtM = Mxx * Myy *Mtt + 2*Mxy*Mxt*Myt - Mxx*(Myt**2) - Myy*(Mxt**2) - Mtt*(Mxy**2)\n",
    "    \n",
    "    H = np.abs(dtM - k*trM**3)\n",
    "    ns = np.ceil(3*sigma)*2 + 1\n",
    "    B_sq = ut.disk_strel(ns)\n",
    "    indeces = []\n",
    "    edges = np.empty(H.shape)\n",
    "    Cond1 = (H[:,:,0]==cv2.dilate(H[:,:,0],B_sq))\n",
    "    \n",
    "    # Condition 2\n",
    "    Cond2 = (H[:,:,0]> theta*H[:,:,0].max())\n",
    "    \n",
    "    # Find edges and return the corresponding points. \n",
    "    edges[:,:,0]= np.logical_and(Cond1, Cond2)\n",
    "    indeces.append(np.where(edges[:,:,0] == 1))\n",
    "    sigm = np.full(indeces[0][0].shape,sigma)\n",
    "    T = np.full(indeces[0][0].shape,0)\n",
    "    bla = np.vstack((indeces[0][0],indeces[0][1],T,sigm))\n",
    "    points = bla.T\n",
    "    for i in range(1,H.shape[2]):\n",
    "        Cond1 = (H[:,:,i]==cv2.dilate(H[:,:,i],B_sq))\n",
    "        # Condition 2\n",
    "        Cond2 = (H[:,:,i] > theta*H[:,:,i].max())\n",
    "        # Edges\n",
    "        edges[:,:,i] = np.logical_and(Cond1, Cond2)\n",
    "        indeces.append(np.where(edges[:,:,i] == 1))\n",
    "        sigm = np.full(indeces[i][0].shape,sigma)\n",
    "        T = np.full(indeces[i][0].shape,i)\n",
    "        bla = np.vstack((indeces[i][1],indeces[i][0],T,sigm))\n",
    "        points = np.concatenate((points,bla.T))\n",
    "    return points    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gabor3D(video ,sigma, t,theta):\n",
    "    w = 4/t\n",
    "    start = int(np.ceil(-2*t))\n",
    "    stop = int(np.ceil(2*t))\n",
    "    time = np.asarray([i for i in range(start,stop)])\n",
    "    hev = np.cos(2*np.pi*time*w) * np.exp(-(time**2) / (2*(t**2)))\n",
    "    hod = np.sin(2*np.pi*time*w) * np.exp(-(time**2) / (2*(t**2)))\n",
    "    H = np.empty(video.shape,dtype='uint8')\n",
    "    \n",
    "    # reshape for be 2D array for normalize\n",
    "    hev = np.reshape(hev,(len(hev),1))\n",
    "    hod = np.reshape(hod,(len(hod),1))\n",
    "    \n",
    "    # normalize with l1 norm\n",
    "    hev_l1 =normalize(hev,norm='l1')\n",
    "    hod_l1 =normalize(hod,norm='l1')\n",
    "    hev = hev / hev_l1\n",
    "    hod = hod / hod_l1\n",
    "    \n",
    "    # filtering frames with 2D Gaussian filters\n",
    "    n = int((np.ceil(3*sigma) * 2 + 1))\n",
    "    G_1D = cv2.getGaussianKernel(n, sigma)\n",
    "    G_2D = G_1D @ G_1D.T\n",
    "    for i in range(video.shape[2]):\n",
    "        Iev = cv2.filter2D(cv2.filter2D(video[:,:,i],-1,G_2D),-1,hev)\n",
    "        #Iev = cv2.filter2D(Iev,-1,hev)\n",
    "        Iod = cv2.filter2D(cv2.filter2D(video[:,:,i],-1,G_2D),-1,hod)\n",
    "        H[:,:,i] = Iev**2 + Iod**2\n",
    "    \n",
    "    ns = np.ceil(3*sigma)*2 + 1\n",
    "    B_sq = ut.disk_strel(ns)\n",
    "    indeces = []\n",
    "    edges = np.empty(H.shape,dtype='uint8')\n",
    "    Cond1 = (H[:,:,0]==cv2.dilate(H[:,:,0],B_sq))\n",
    "    \n",
    "    # Condition 2\n",
    "    Cond2 = (H[:,:,0]> theta*H[:,:,0].max())\n",
    "    \n",
    "    # Find edges and return the corresponding points. \n",
    "    edges[:,:,0]= np.logical_and(Cond1, Cond2)\n",
    "    indeces.append(np.where(edges[:,:,0] == 1))\n",
    "    sigm = np.full(indeces[0][0].shape,sigma)\n",
    "    T = np.full(indeces[0][0].shape,0)\n",
    "    bla = np.vstack((indeces[0][0],indeces[0][1],T,sigm))\n",
    "    points = bla.T\n",
    "    for i in range(1,H.shape[2]):\n",
    "        Cond1 = (H[:,:,i]==cv2.dilate(H[:,:,i],B_sq))\n",
    "        # Condition 2\n",
    "        Cond2 = (H[:,:,i] > theta*H[:,:,i].max())\n",
    "        # Edges\n",
    "        edges[:,:,i] = np.logical_and(Cond1, Cond2)\n",
    "        indeces.append(np.where(edges[:,:,i] == 1))\n",
    "        sigm = np.full(indeces[i][0].shape,sigma)\n",
    "        T = np.full(indeces[i][0].shape,i)\n",
    "        bla = np.vstack((indeces[i][1],indeces[i][0],T,sigm))\n",
    "        points = np.concatenate((points,bla.T))\n",
    "        \n",
    "    return points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Ανίχνευση τοπικών χαρακτηριστικών με χρήση του Harris-Stephens ανιχνευτή."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 3\n",
    "s = 1.5\n",
    "t = 0.7\n",
    "k = 0.0005\n",
    "theta = 0.05\n",
    "\n",
    "points = Harris_Stephens(vid,sigma , s , t, k ,theta)\n",
    "ut2.show_detection(vid,points,save_path=\"C:\\\\Users\\\\Andrew\\\\anaconda3\\\\envs\\\\cv_lab\\\\CV20_Lab2\\\\Results\\\\Boxing2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ανίχνευση σημείων ενδιαφέροντος χρησιμοποιώντας Gabor φίλτρα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\anaconda3\\envs\\cv_lab\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "sigma = 2.5\n",
    "t = 1.3\n",
    "\n",
    "theta = 0.2\n",
    "points = Gabor3D(vid,sigma, t,theta)\n",
    "path = \"C:\\\\Users\\\\Andrew\\\\anaconda3\\\\envs\\\\cv_lab\\\\CV20_Lab2\\\\Results\\\\Boxing_Gabor2\"\n",
    "ut2.show_detection(vid,points,save_path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Χωρο-χρονικοί Ιστογραφικοί Περιγραφητές\n",
    "2.2.1 - 2.2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Χωρο-χρονικοί Ιστογραφικοί Περιγραφητές"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Descriptor(video,isHOG,rho,nbins, epsilon, d_x0, d_y0,neighbor_size,points,desc_cells_per_dim=2,reps=15):\n",
    "    weights = np.array([-1,0,1])\n",
    "    # Normalize to [0,1]\n",
    "    Gx, Gy = np.empty(video.shape),np.empty(video.shape)\n",
    "    Im = video.astype(np.float)/255\n",
    "    dx,dy = np.empty(Im.shape),np.empty(Im.shape)\n",
    "    # Calculate the derivatives of each frame using the mask [-1,0,1]T\n",
    "    if isHOG:\n",
    "        Ix = convolve1d(Im,weights,axis=0)\n",
    "        Iy = convolve1d(Im,weights,axis=1)\n",
    "    else:\n",
    "        for i in range(video.shape[2] - 1 ):\n",
    "            dx[:,:,i],dy[:,:,i] = lk.Lucas_Kanade(Im[:,:,i],Im[:,:,i+1], d_x0, d_y0, rho, epsilon, reps, False, i+1, \"saveFolder\")\n",
    "    \n",
    "    window = int(np.floor(np.ceil(neighbor_size)))\n",
    "    descriptors = [] \n",
    "    # Define the boundaries of Gx and Gy \n",
    "    for i in range(1,points.shape[0]):\n",
    "        px = int(points[i,0])\n",
    "        py = int(points[i,1])\n",
    "        t = int(points[i,2])\n",
    "        if t == Im.shape[2] and isHOG == 0 :\n",
    "            continue\n",
    "        if px - window < 0:\n",
    "            lower_x_bound = 0\n",
    "        else:\n",
    "            lower_x_bound =  int(px - window)\n",
    "    \n",
    "        if px + window > Im.shape[1] :\n",
    "            upper_x_bound = Im.shape[1]\n",
    "        else:\n",
    "            upper_x_bound =  int(px + window)\n",
    "    \n",
    "        if py - window < 0:\n",
    "            lower_y_bound = 0\n",
    "        elif py > Im.shape[0]:\n",
    "            continue\n",
    "        else:\n",
    "            lower_y_bound =  int(py - window)\n",
    "            \n",
    "        if py + window > Im.shape[0]:\n",
    "            upper_y_bound = Im.shape[0]\n",
    "        else:\n",
    "            upper_y_bound =  int(py + window)\n",
    "        \n",
    "        if isHOG:\n",
    "            Gx = Ix[lower_y_bound: upper_y_bound, lower_x_bound: upper_x_bound, t]\n",
    "            Gy = Iy[lower_y_bound: upper_y_bound, lower_x_bound: upper_x_bound, t]\n",
    "        else:\n",
    "            Gx = dx[lower_y_bound: upper_y_bound, lower_x_bound: upper_x_bound, t]\n",
    "            Gy = dy[lower_y_bound: upper_y_bound, lower_x_bound: upper_x_bound, t]\n",
    "\n",
    "        desc_dim = np.array([desc_cells_per_dim, desc_cells_per_dim] )\n",
    "        \n",
    "        descriptors.append(ut2.orientation_histogram(Gx, Gy, nbins, desc_dim,0,0))\n",
    "        \n",
    "    return descriptors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Δημιουργία συνάρτησης feature_extracrion η οποία θα δέχεται ένα βίντεο, μια παράμετρο isHarris που επιλέγει ποιος ανιχνευτής θα χρησιμοποιηθεί για την εύρεση των σημείων ενδιαφέροντος (1 για τον Harris, 0 για τον Gabor), καθώς και τις απαραίτητες παραμέτρους που χρειάζονται οι ανιχνευτές.\n",
    "Η έξοδος της συνάρτησης είναι ο HOG/HOF περιγραφητής σε μορφή 2D numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(video,isHarris,sigma,nbins, s , t, k ,theta,rho, epsilon, d_x0, d_y0,neighbor_size,desc_cells_per_dim, reps ):\n",
    "    # calculate the points\n",
    "    if isHarris:\n",
    "        points = Harris_Stephens(video,sigma , s , t, k ,theta)\n",
    "    else:\n",
    "        points = Gabor3D(video,sigma, t,theta)\n",
    "   \n",
    "    # apply HOG and HOF descriptors\n",
    "    HoG_desc = Descriptor(video,1,rho,nbins, epsilon, d_x0, d_y0,neighbor_size,points,desc_cells_per_dim ,reps)\n",
    "    HoF_desc = Descriptor(video,0,rho,nbins, epsilon, d_x0, d_y0,neighbor_size,points,desc_cells_per_dim ,reps)\n",
    "    \n",
    "    # convert to 2D numpy array\n",
    "    HoG_Desc = np.asarray(HoG_desc,dtype='uint8')\n",
    "    HoF_Desc = np.asarray(HoF_desc,dtype='uint8')\n",
    "    \n",
    "    # create HOG/HOF descriptor\n",
    "    HoG_HoF = np.empty((2*HoG_Desc.shape[0],HoG_Desc.shape[1]),dtype='uint8')\n",
    "    HoG_HoF = np.concatenate((HoG_Desc,HoF_Desc))\n",
    "    \n",
    "    return HoG_HoF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η συνάρτηση create_train_test παίρνει ως όρισμα το path του αρχείου στο οποίο βρίσκονται τα αρχεία για το training και test σετ και επιστρέφει σε μορφή τα αρχεία των βίντεο καθώς και τα labels του κάθε βίντεο."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(path):\n",
    "    training_video_paths = []\n",
    "    test_video_paths = []\n",
    "    training_labels = []\n",
    "    test_labels = []\n",
    "    with open(path + \"\\\\traininng_videos.txt\", \"r\") as filestream:\n",
    "        for line in filestream:\n",
    "            currentline = line.split(\"_\")\n",
    "            paths = path + currentline[1] + \"\\\\\" + line\n",
    "            training_video_paths.append(paths)\n",
    "            training_labels.append(currentline[1])\n",
    "\n",
    "    with  open(path + \"\\\\test_videos.txt\", \"r\") as filestream:\n",
    "        for line in filestream:\n",
    "            currentline = line.split(\"_\")\n",
    "            paths = path + currentline[1] + \"\\\\\" + line\n",
    "            test_video_paths.append(paths) \n",
    "            test_labels.append(currentline[1])\n",
    "    \n",
    "    return training_video_paths, training_labels,test_video_paths,test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3: Κατασκευή Bag of Visual Words και χρήση Support Vector Machines για την ταξινόμηση δράσεων\n",
    "##### Ταξινόμηση δράσεων χρησιμοποιώντας  τον Harris-Stephens ανιχνευτή"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "nframes = 200\n",
    "nbins = 9\n",
    "isHarris = 1\n",
    "sigma = 4\n",
    "neighbor_size = 4*sigma\n",
    "d_x0, d_y0 = 0,0\n",
    "rho, epsilon = 1, 0.05\n",
    "s = 1.5\n",
    "t = 0.7\n",
    "k = 0.005\n",
    "theta = 0.05\n",
    "D = 500 # initialize the number of centroids that will be used for the BoVW \n",
    "desc_cells_per_dim = 2\n",
    "reps = 15\n",
    "####################################################3\n",
    "##### Create train and test datasets\n",
    "##### The training_video_paths is a list that holds the paths for reading the video\n",
    "##### Respectively the test_video_paths\n",
    "path = \"C:\\\\Users\\\\Andrew\\\\anaconda3\\\\envs\\\\cv_lab\\\\CV20_Lab2\\\\cv20_lab2_part2_material\\\\\"\n",
    "training_video_paths,train_labels,test_video_paths,test_labels = create_train_test(path)\n",
    "\n",
    "for path in training_video_paths:\n",
    "    video = ut2.read_video(path,nframes,0)\n",
    "    desc_train = feature_extraction(video,isHarris,sigma,nbins, s , t, k ,theta,rho, epsilon, d_x0, d_y0,neighbor_size,desc_cells_per_dim, reps)\n",
    "    \n",
    "for path in test_video_paths:\n",
    "    print(path)\n",
    "    video = ut2.read_video(path,nframes,0)\n",
    "    desc_test = feature_extraction(video,isHarris,sigma,nbins, s , t, k ,theta,rho, epsilon, d_x0, d_y0,neighbor_size,desc_cells_per_dim, reps)\n",
    "\n",
    "############################################################3\n",
    "####### Calculate the BoVW for training and test datasets \n",
    "####### Find the accuracy and predictions using svm classifier\n",
    "bow_train, bow_test = ut2.bag_of_words(desc_train, desc_test, num_centers=D)\n",
    "    \n",
    "accuracy, pred = ut2.svm_train_test(bow_train, train_labels, bow_test, test_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the results for using Harris-Stephens detector and HOG/HOF descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 69.23076923076923 %\n",
      "predictions: ['running' 'walking' 'boxing' 'running' 'running' 'boxing' 'boxing'\n",
      " 'boxing' 'boxing' 'boxing' 'walking' 'walking' 'boxing']\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy is:',100.0*accuracy,\"%\")\n",
    "print('predictions:',pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ταξινόμηση δράσεων χρησιμοποιώντας τον Gabor ανιχνευτή"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "nframes = 200\n",
    "nbins = 9\n",
    "isHarris = 0\n",
    "sigma = 2.5\n",
    "neighbor_size = 4*sigma\n",
    "d_x0, d_y0 = 0,0\n",
    "rho, epsilon = 1, 0.05\n",
    "s = 1.5\n",
    "t = 1.3\n",
    "k = 0.005\n",
    "theta = 0.2\n",
    "D = 500 \n",
    "desc_cells_per_dim = 2\n",
    "reps = 15\n",
    "path = \"C:\\\\Users\\\\Andrew\\\\anaconda3\\\\envs\\\\cv_lab\\\\CV20_Lab2\\\\cv20_lab2_part2_material\\\\\"\n",
    "training_video_paths,train_labels,test_video_paths,test_labels = create_train_test(path)\n",
    "desc_train_Gabor = []\n",
    "for path in training_video_paths[3:]:\n",
    "    video = ut2.read_video(path,nframes,0)\n",
    "    feats = feature_extraction(video,isHarris,sigma,nbins, s , t, k ,theta,rho, epsilon, d_x0, d_y0,neighbor_size,desc_cells_per_dim, reps)\n",
    "    desc_train_Gabor.append(feats)\n",
    "\n",
    "#desc_test_Gabor = []    \n",
    "for path in test_video_paths:\n",
    "    video = ut2.read_video(path,nframes,0)\n",
    "    feats = feature_extraction(video,isHarris,sigma,nbins, s , t, k ,theta,rho, epsilon, d_x0, d_y0,neighbor_size,desc_cells_per_dim, reps)\n",
    "    desc_test_Gabor.append(feats)\n",
    "\n",
    "bow_train_Gabor, bow_test_Gabor = ut2.bag_of_words(desc_train_Gabor, desc_test_Gabor, num_centers=D)\n",
    "    \n",
    "accuracy, pred = ut2.svm_train_test(bow_train_Gabor, train_labels, bow_test_Gabor, test_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 76.92307692307692 %\n",
      "predictions: ['running' 'running' 'running' 'running' 'running' 'running' 'boxing' 'boxing' 'boxing' 'boxing' 'walking' 'walking' 'running']\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy is:',100.0*accuracy,\"%\") \n",
    "print('predictions:', pred )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cv_lab] *",
   "language": "python",
   "name": "conda-env-cv_lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
